# -*- coding: utf-8 -*-
"""Deep Learning CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YgGOCzQKDck5WdG0Ltv6BITZm3XE2__v
"""

import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import pandas as pd
from PIL import Image
import scipy.misc
import io
from skimage import color
from skimage import io
import cv2

# Importing the Keras libraries and packages
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image

!pip install PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client.
# This only needs to be done once in a notebook.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

!ls

#DRIVE_FILE_ID for test_set.zip
#fileId = drive.CreateFile({'id': '1f6zfBtFNDSu3q7MpirzHd78zHknIj2xD'})
#fileId.GetContentFile('test_set.zip')  # Save Drive file as a local file

#!unzip test_set.zip -d ./

#DRIVE_FILE_ID for training_set.zip
#fileId = drive.CreateFile({'id': '1Nt8WZ73nI5drbWJnyX0XbAPWY_1j7NeD'})
#fileId.GetContentFile('training_set.zip')  # Save Drive file as a local file

#!unzip training_set.zip -d ./

#DRIVE_FILE_ID for test_set_small.zip
fileId = drive.CreateFile({'id': '1L64mHwSSEaqIo1nhleB17wIR59XcTEEn'})
fileId.GetContentFile('test_set_small.zip')  # Save Drive file as a local file

!unzip test_set_small.zip -d ./

#DRIVE_FILE_ID for training_set_small.zip
fileId = drive.CreateFile({'id': '1nUz6mnuqlt1ttKPtn0CXFtlOj5Nln_M9'})
fileId.GetContentFile('training_set_small.zip')  # Save Drive file as a local file

!unzip training_set_small.zip -d ./

#create classifier
classifier = Sequential()
classifier.add(Conv2D(filters = 32, kernel_size = (5, 5), strides = (2,2), input_shape = (100, 100, 3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Flatten())
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dropout(0.2))
classifier.add(Dense(units = 1, activation = 'sigmoid'))
classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

classifier.summary()

batch = 16
train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)
test_datagen = ImageDataGenerator(rescale = 1./255)
training_set = train_datagen.flow_from_directory('training_set_small', target_size = (100, 100), batch_size = batch, class_mode = 'binary')
test_set = test_datagen.flow_from_directory('test_set_small', target_size = (100, 100), batch_size = batch, class_mode = 'binary')

classifier.fit_generator(training_set, steps_per_epoch = 8000, epochs = 7, validation_data = test_set, validation_steps = 2000)

from sklearn.metrics import confusion_matrix
num_of_test_samples = 2000

Y_pred = classifier.predict_generator(test_set, num_of_test_samples // batch)
y_pred = np.round(Y_pred,decimals = 0)

print('Confusion Matrix')
print(confusion_matrix(test_set.classes, y_pred))

from google.colab import files
uploaded = files.upload()

test_image = image.load_img('female.27.jpg', target_size = (100, 100))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = classifier.predict(test_image)
training_set.class_indices
if (result[0][0] == 1):
  print('male')
else:
  print('female')

import matplotlib.pyplot as plt
plt.plot([91,92.01,96.54,97.64,98.25,98.56,98.77,98.97])
plt.plot([89.35,89.35,90.05,89.85,90.2,90.85,91.25,91.7])
plt.title('Model accuracy')
plt.ylabel('Accuracy Rate (%)')
plt.xlabel('Epoch')
plt.xlim(1,7.5)
plt.ylim(87,100)
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot([19.77,19.77,9.51,6.43,5,4.13,3.58,3.05])
plt.plot([33.94,33.94,34.87,48.04,43.42,48.83,53.6,44.46])
plt.title('Model Loss')
plt.ylabel('Loss Rate (%)')
plt.xlabel('Epoch')
plt.xlim(1,7.5)
plt.ylim(0,55)
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()